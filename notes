By Pavan Wankhade
================
This document is here to share command history and example scripts
=======================================================


LAB Details:

RPS  Lab Access URL:   https://cloud.cdp.rpsconsulting.in/console/#/


AWS Login URL : https://epsh2.signin.aws.amazon.com/console


Day 1 
=====


### installation of Terraform on Centos LAB

$ su - root                 ### PAssword is “rps@12345”

# yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
# yum -y install terraform 
# terraform --version
# logout                                                #### will take you 
$ terraform --version

Ref : https://www.terraform.io/downloads
Providers in terraform:  https://registry.terraform.io/browse/providers

================================================


### Demo 1 : For Local Provisioners and local execuators

  12  mkdir example1-local
   13  cd example1-local/
   14  pwd
   15  vi main.tf
resource "null_resource" "operation1"{
provisioner "local-exec" {
command = "echo 'Hello all' > file1.txt"
}
}


   16  terraform init
   17  terraform plan
   18  ls
   19  terraform apply
   20  ls
   21  cat file1.txt
   22  cat terraform.tfstate
===========================================
### Note down AWS Credentials on on notepad file 
Region
Access key
Secret key
=====================
Demo 2: 

### AWS s3 resource creation 
;

    5  mkdir awsS3practice
    6  cd awsS3practice/
    7  pwd

    8  vi main.tf
 provider "aws" {
region = "ap-south-1"
access_key = "*****"
secret_key = "*****"
}

resource "aws_s3_bucket" "pavansbucket" {
bucket = "pavan-terraform-training01"
tags = {
Name = "pavanTrainer"
Environment = "development"
}
}

resource "aws_s3_bucket_acl" "pavansbucketACL"{
acl = "private"
bucket = aws_s3_bucket.pavansbucket.id
}

---------------------------------------------------------------------------------

   9  ls -la
   10  terraform init
   20  terraform plan
   21  ls -la
   22  terraform apply
   23  ls -la
   24  vi terraform.tfstate
   29  terraform destroy
   =======================================

### Day 2:
================

## Local executors with Null_Resource
======================================
  37  mkdir TERRAFORM_Practice
   38  cd TERRAFORM_Practice/


   39  mkdir new_project
   40  cd new_project/
  
 41  vi myterraform.tf
resource "null_resource" "opt1"{

provisioner "local-exec" {
command = "echo 'This is Terraform Training' > training.txt"
}
}

resource "null_resource" "opt2"{

provisioner "local-exec" {
command = "echo 'Pavan Wankhade is the trainer for this training' > trainer.txt"
}
}

-------------------------------------------------

   42  ls
   43  terraform init
   44  terraform apply
   45  ls
   46  cat training.txt
   47  cat terraform.tfstate

### lets create a new tf file


   58  vi myterraform1.tf
resource "null_resource" "opt3"{

provisioner "local-exec" {
command = "echo 'This is Terraform Training' > training1.txt"
}
}

------------------------------------------------------
   61  ls
   62  terraform apply
   63  ls
   64  cat terraform.tfstate
   65  cat terraform.tfstate.backup
   66  terraform show
   67  ls

 =================================================================
Demo:

### Using environment argument in Local-Exec

$ vi myexample.tf

resource "null_resource" "newOperation" {
provisioner "local-exec"{
command = "echo $ENV1 $ENV2 $ENV3 >> myenv.txt"
environment = {
ENV1 = "Training"
ENV2 = "true"
ENV3 = 1
}
}
}
--------------------------
Terraform apply need to do to apply this code
-------------------------
$ cat myenv.txt
Note : environment - (Optional) block of key value pairs representing the environment of the executed command. inherits the current process environment.
==============================================================
Demo :
### Working_dir argument with Local_execuator
Example:
===========
  79  vi /home/rps/myscript.sh
hostname >> ~/output.txt
date >> ~/output.txt
free -h >> ~/output.txt

--------------------------------------------

   80  vi myexample1.tf

resource "null_resource" "runningScript" {
provisioner "local-exec" {
command = "sh myscript.sh"
working_dir = "/home/rps/"
}
}

-----------------------------------------------------

   81  terraform apply
   87  cat /home/rps/output.txt
   88  cat /home/rps/myscript.sh

=======================================

#### Input variables 
====================
String
Number
Boolean
## special types
List
Map


=================
Demo:   String and Number type variables
-----------------------------

  95  mkdir example-vars
   96  cd example-vars/
   97  ls
   98  vi main.tf
variable "myvar" {
type = string
default = "This is Team GTS for Terraform"
}

variable "yourvar" {
type = number
default = 30
}

resource "null_resource" "operation1" {
provisioner "local-exec" {
command = "echo ${var.myvar} having ${var.yourvar} members > file1.txt"
}
}

-------------------------------------------------
    101  terraform init
  102  terraform apply
  103  ls
  104  cat file1.txt


==========================================
Extra : Example of vars of type bool and hiding output of vars from Plan and Apply Output with sensitive vars


$ cat main.tf
variable "myvar" {
type = string
default = "This is Team GTS for Terraform"
sensitive = true
}

variable "yourvar" {
type = number
default = 30
}

variable "newvar" {
type = bool
default = true
}


resource "null_resource" "operation1" {
provisioner "local-exec" {
command = "echo ${var.myvar} having ${var.yourvar} members and newvar is ${var.newvar} > file1.txt"
}
}

==============================================================

Demo : 
### variables with type List and Map 

$ vi sample.tf
variable "users" {
type = list
default = ["root","rps","pavan"]
}

variable "flavors" {
type = map
default = {
"flavor1" = "1xCPU-1GB"
"flavor2" = "2xCPU-2GB"
"flavor9" = "8xCPU-64GB"
}
}


resource "null_resource" "operationy" {
provisioner "local-exec" {
command = "echo configurations available are : ${var.flavors["flavor1"]} , ${var.flavors["flavor2"]} , ${var.flavors["flavor9"]} >> file2.txt"
}
}
resource "null_resource" "operationx" {
provisioner "local-exec" {
command = "echo Users are : ${var.users[0]} , ${var.users[1]} , ${var.users[2]} >> file1.txt"
}
}

==========================================
### Variables defined without Type :  can read input and decide type intelligently 
### Variables values can be pass with Command line with terra form apply or plan

=====================================================

$ cat newfile.tf
variable "set_password" {
default = true
}

resource "null_resource" "operation3"{
provisioner "local-exec" {
command = "echo values of set_password var is ${var.set_password} >> file1.txt"
}
}

--------------------------------------------
$ terraform  apply
$ terraform destroy
$ terraform apply -var set_password=false                 ## Command line vars
======================================

#####
Demo : TFVARS
===============

 150  cd ..
  151  ls
  152  mkdir decent_project
  153  cd decent_project/
  154  vi vars.tf
variable "myvar" {
type = string
}

variable "yourvar" {
type = number
}

------------------------------------------------------

  155  vi terraform.tfvars
myvar = "Hello all , Welcome to Terraform"
yourvar = 100

---------------------------------------------

  156  ls
  157  vi main.tf
resource "null_resource" "operation1" {
provisioner "local-exec" {
command = "echo ${var.myvar} having ${var.yourvar} members > file1.txt"
}
}

----------------------------------------------

  158  terraform init
  164  terraform plan
  177  terraform apply --auto-approve

====================================================================

#### AWS VPC Demo Project

 187  cd ..
  188  ls
  189  mkdir example-aws-vpc
  190  cd example-aws-vpc/
  191  ls
  192  vi credentials.tf
provider "aws" {
region = "ap-south-1"
access_key = "**********"
secret_key = "***************"
}
--------------------------------------------------------


  193  vi vars.tf
variable "mycidr" {
type = string
description = "CIDR block for proposed new vpc By pavan"
}

---------------------------------------

  194  vi terraform.tfvars
mycidr = "21.21.0.0/16"
--------------------------------------------
  195  vi main.tf
resource "aws_vpc" "pavan-vpc"{
cidr_block = var.mycidr
instance_tenancy = "default"
tags = {
Name = "Pavan-vpc"
}
}

---------------------------------------------------------------

  196  ls
  197  terraform init
  198  vi main.tf
  199  terraform init
  200  terraform plan
  201  terraform apply --auto-approve
  202  ls
  203  cat terraform.tfstate
  204  ls
  205  terraform destroy
  203  cat terraform.tfstate
===================================================
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Day 3
========

========
#### Create your Github personal account and Add ssh key of your node to its settings


$  su - root              ===> password is   rps@12345
#    yum install git -y             
#     logout   

=============
  258  git --version

  260  whoami
  261  ssh-keygen                 ###  Press “Enter”  when it ask any question fro default values

  262  cat /home/rps/.ssh/id_rsa.pub

## Copy the Key and On github portal 
(Right Upper corner Down arrow beside your profile picture/avatar )

 Go to Settings ⇒ In “Access” Section on left panel ⇒ “SSH and GPG Keys” ⇒ Add “New Ssh Key”  ⇒ Copy and paste you ssh public key into and save
 
Note : Public key need to copy from “ cat /home/rps/.ssh/id_rsa.pub” command   


========================================
####  Git Config for developers name and EmailID


257  git config --global user.name pavansw
  258  git config --global user.email pavanwankhade4u@gmail.com
============================================  

  228  git clone git@github.com:pavansw/TerraformSampleProjectGTS.git
 229  ls
  230  cd TerraformSampleProjectGTS/
  231  ls
  232  pwd
  233  ls -la
  234  touch .gitignore

  247  vi credentials.tf
provider "aws" {
region = "ap-south-1"
access_key = "**********"
secret_key = "***************"
}
--------------------------------------------------------


  248  vi variables.tf
variable "mycidr" {
type = string
description = "CIDR block for proposed new vpc By pavan"
}

---------------------------------------
  249  vi terraform.tfvars
mycidr = "21.21.0.0/16"
--------------------------------------------
  195  vi main.tf
resource "aws_vpc" "pavan-vpc"{
cidr_block = var.mycidr
instance_tenancy = "default"
tags = {
Name = "Pavan-vpc"
}
}
-------------------------------------------------------------------  
251  ls -la
 275  echo ".terraform" >> .gitignore
  286  echo ".terraform/*" >> .gitignore

  252  echo "credentials.tf" >> .gitignore
  253  echo "terraform.tfvars" >> .gitignore


  254  vi README.md
# Type some Instructions about variables  and values

  255  git add .
  261  git commit -m "Initial Project for VPC AWS"

262  git push origin master
++++++++++++++++++++++++++
## Check on GitHub
============================================
 263  terraform init
  264  terraform plan
  265  terraform apply --auto-approve
  299  git add .

  301  git commit -m "Fresh VPC Created"
  302  git push origin master
====================================

#### Whenever you change Anything in the Terraform Project Directory you need to do “git add .”  , “git commit -m <Some Msg>” , git push origin master
======================================================


_________________________________________________________________
Day 4:

Loop with Count 
==============================


  383  mkdir example_loop
  384  cd example_loop/
  385  ls
##  386  cp ../TerraformSampleProjectGTS/credentials.tf .
  387  ls
  388  cat credentials.tf            ### write credentials
  389  vi example.tf

## example1 with List


variable "names" {
type = list
default = ["pavan-user1","pavan-user2","pavan-user3"]
description = "New User Accounts for IAM"
}

resource "aws_iam_user" "myusers" {
count = length(var.names)
name = var.names[count.index]
}
## example with count appended in username

resource "aws_iam_user" "usersCreation"{
count = 6
name = "GTS${count.index}"
}

------------------------------------------------
  391  terraform init
  392  terraform validate
  393  terraform plan
  394  terraform apply --auto-approve
  395  cat terraform.tfstate
 407  terraform destroy --auto-approve

===========================================================
#### AWS S3 Bucket and Bucket Object upload - 

  447  cd ..
  448  mkdir exampleS3
  449  cd exampleS3/
  450  ls
  451  cp ../example_loop/credentials.tf .

  458  vi main.tf
resource "aws_s3_bucket" "mybucket" {
bucket = "pavan-terraform-training01"
tags = {
Name = "pavanTrainer"
Environment = "Test"
}
}

resource "aws_s3_bucket_acl" "mybucketacl"{
acl = "private"
bucket = aws_s3_bucket.mybucket.id
}

---------------------------------------------------------------------

  459  terraform init
  460  terraform plan
  461  terraform apply --auto-approve



####  Lets upload one object on the bucket

  462  ls
  463  echo "This is My webpage: PAVAN" > index.html
  464  ls
  465  vi upload_object.tf
resource "aws_s3_object" "myobject" {
  bucket = aws_s3_bucket.mybucket.id
  key = "mywebpage"
  acl = "private"  # or it can be "public-read"
  source = "index.html"
  etag = filemd5("index.html")    ### optional field used for encryption of object
}

--------------------------------------------------------------

  466  terraform plan
  467  vi upload_object.tf
  468  terraform plan
  469  terraform apply --auto-approve

###   Bulk upload data to S3 bucket and use of    for each   loop
  470  ls
  471  mkdir mydata
  472  touch mydata/sample{1..3}.doc
  473  ls
  474  ls mydata/
  475  ls
  476  vi upload_object.tf

resource "aws_s3_object" "myobject1" {

for_each = fileset("mydata/","*")

  bucket = aws_s3_bucket.mybucket.id
  key = each.value
  acl = "private"
  source = "mydata/${each.value}"
  etag = filemd5("mydata/${each.value}")
}

------------------------------------------------------------------------------

  477  terraform plan
  478  terraform apply --auto-approve
  479  terraform destroy --auto-approve
============================================================

### EXTRAS :      depends_on = [****** some resource Name *****]

## depends_on helps to create dependency between resources 
Example :  relevance with previous demo

  resource "aws_s3_object" "myobject" {

  depends_on = [aws_s3_bucket.mybucket]
  bucket = aws_s3_bucket.mybucket.id
  key = "mywebpage"
  acl = "private"  # or it can be "public-read"
  source = "index.html"
  etag = filemd5("index.html")    # optional field used for encryption of object
}

=========================================
================
## Little large infra with more components line VPC, SG, Gateway, route, Subnets, etc….

 491  cd ..
  492  ls
  493  mkdir example-vpc-ec2
  494  cd example-vpc-ec2/
  495  cp ../example_loop/credentials.tf .
  496  ls
  497  cat credentials.tf
  498  vi main.tf
resource "aws_vpc" "vpc" {
        cidr_block = "172.0.0.0/16"
        tags = {
        Name = "Pavan-vpc1"
        }
}

resource "aws_internet_gateway" "gateway"{
        vpc_id = aws_vpc.vpc.id
}

resource "aws_route" "route"{
        route_table_id = aws_vpc.vpc.main_route_table_id
        destination_cidr_block = "0.0.0.0/0"
        gateway_id = aws_internet_gateway.gateway.id
}

data "aws_availability_zones" "availableAZ"{}

#output "AZs" {
#       description = "lets find out no of  AZ in region"
#       value = data.aws_availability_zones.availableAZ.names
#}

resource "aws_subnet" "main" {
        count = length(data.aws_availability_zones.availableAZ.names)
        vpc_id = aws_vpc.vpc.id
        cidr_block = "172.0.${count.index}.0/24"
        map_public_ip_on_launch = true
        availability_zone = element(data.aws_availability_zones.availableAZ.names,count.index)
}

resource "aws_security_group" "default" {
        name = "http-https-ssh-allow"
        description = "Allow HTTP, HTTPS and SSH Connections"
        vpc_id = aws_vpc.vpc.id
        ingress {
                from_port = 22
                to_port = 22
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 80
                to_port = 80
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 443
                to_port = 443
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }
}


--------------------------------------------------------------------------------

  499  terraform validate
  500  terraform init
  501  terraform validate
  502  vi main.tf
  503  terraform validate
  504  terraform plan
  505  terraform apply --auto-approve

 553  terraform destroy --auto-approve
===================================================
##  Extras :  

To read and manage state files resources entries :

  540  terraform state list
  541* terraform state show aws_vpc.vpc
  542  terraform state list
  543  terraform state show aws_route.route
  544  terraform state --help
  545  terraform state list

Extras : 
### If any resource you want to remove from terraform directory reach , means removing any resource from state file but not from read world the you can use “terraform state rm ”   :
Example      “ terraform state rm aws_security_group.default”
  547  terraform state list

Extras : 
### Terraform Import option is there to take Real world resources under terraform and update state
================================================================

########################  AWS RDS Database Service #######################
### Using “ Environment variables for username and password like sensitive data”

 561  cd mysql
  562  ls
  563  ll
  564  cat credentials.tf

====================================
  565  vi variables.tf
variable "username" {
type = string
sensitive = true
}

variable "password" {
type = string
sensitive = true
}


####
variable "identifier" {
  default     = "mydb-rds"
  description = "Identifier for your DB"
}

variable "storage" {
  default     = "10"
  description = "Storage size in GB"
}

# variable "engine" {
#  default     = "mysql"
#  description = "Engine type, here it is mysql"
#}

#variable "engine_version" {
#  description = "Engine version"

#  default = {
#    mysql    = "5.7.21"
#  }
#}

#variable "instance_class" {
#  default     = "db.t2.micro"
#  description = "Instance class"
#}

#variable "db_name" {
#  default     = "myfirstdb"
#  description = "db name"
#}

variable "subnet_1_cidr" {
  default     = "172.31.48.0/20"
  description = "Your AZ"
}

variable "subnet_2_cidr" {
  default     = "172.31.64.0/20"
  description = "Your AZ"
}

variable "az_1" {
  default     = "ap-south-1a"
  description = "Your Az1, use AWS CLI to find your account specific"
}

variable "az_2" {
  default     = "ap-south-1b"
  description = "Your Az2, use AWS CLI to find your account specific"
}

#variable "vpc_id" {
#  description = "Your VPC ID"
#  default = aws_vpc.default.id
#}

variable "cidr_blocks" {
  default     = "0.0.0.0/0"
  description = "CIDR for sg"

}

variable "sg_name" {
  default     = "my-rds-sg"
  description = "Tag Name for sg"
}

=====================================================


  566  vi main.tf
resource "aws_vpc" "default" {
cidr_block = "172.31.0.0/16"
instance_tenancy = "default"
tags = {
Name = "Pavan-vpc"
}
}

resource "aws_db_instance" "default" {
  depends_on             = [aws_security_group.default]
  identifier             = var.identifier
  allocated_storage      = var.storage
  engine                 = "mysql"
  engine_version         = "5.7.21"
 # engine_version         = "${lookup(var.engine_version, var.engine)}"
  instance_class         = "db.t2.micro"
 # instance_class         = "${var.instance_class}"
  db_name                = "myfirstdb"
  username               = var.username
  password               = var.password
  vpc_security_group_ids = [aws_security_group.default.id]
  db_subnet_group_name   = aws_db_subnet_group.default.id
  skip_final_snapshot = "true"
}

resource "aws_db_subnet_group" "default" {
  name        = "main_subnet_group"
  description = "Our main group of subnets"
  subnet_ids  = [aws_subnet.subnet_1.id, aws_subnet.subnet_2.id]
}
resource "aws_subnet" "subnet_1" {
  vpc_id            = aws_vpc.default.id
  cidr_block        = var.subnet_1_cidr
  availability_zone = var.az_1

  tags = {
    Name = "main_subnet1"
  }
}

resource "aws_subnet" "subnet_2" {
  vpc_id            = aws_vpc.default.id
  cidr_block        = var.subnet_2_cidr
  availability_zone = var.az_2

  tags = {
    Name = "main_subnet2"
  }
}
resource "aws_security_group" "default" {
  name        = "main_rds_sg"
  description = "Allow all inbound traffic"
  vpc_id      = aws_vpc.default.id

  ingress {
    from_port   = 0
    to_port     = 65535
    protocol    = "TCP"
    cidr_blocks = [var.cidr_blocks]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = var.sg_name
  }
}

=====================================
  571  export TF_VAR_username=pavan
  572  export TF_VAR_password=mypass12345
  573  terraform init
  574  terraform plan
  575  terraform apply
  579  vim terraform.tfstate
  580  terraform destroy
=====================================================================================================================================

DAY5 
=========

Demo : GitHub Provider for Terraform
==============================
Imp:   Create Security token from Git Hub Developers settings for Access
Steps:  Go to Account Settings : right upper corner with you profile picture / Avatar ⇒ Settings ⇒
		“Developer Settings” ⇒
		“Personal access tokens” ⇒
			 Create new token and copy it for the further use  “Atleast Repository access  and Delete repo should be provided for this demo”

---------


  630  mkdir example-GitHUb
  631  cd example-GitHUb/
  632  vi mygithub.tf
terraform {
required_providers {

        github = {
                source = "integrations/github"
                version = "4.3.2"
                }
        }
}

provider "github" {
        token = "***************"
}

resource "github_repository" "repo1" {
        name = "terraform_GTS_Training_10thJune"
        visibility = "public"
}

========================================================================

  633  ll
  634  terraform validate
  635  terraform init
  636  terraform validate
  637  terraform plan
  638  terraform plan -out=myplan
  639  ls
  640  vi myplan
  641  terraform apply myplan
  642  ls
  643  vi terraform.tfstate
  644  terraform destroy


================================================================================

###Terraform Module   : 


### small  Demo

  650  mkdir highLevel
  651  cd highLevel/
  652  mkdir aws_Site1
  653  cd aws_Site1/
  654  pwd
  658  vi credentials.tf
provider "aws" {
region = "ap-south-1"
access_key = "************"
secret_key = "*********************"
}


---------------------------------------------------------------------------

  660  vi main.tf

resource "aws_vpc" "vpc" {
        cidr_block = var.cidr_block                            ## this value will come from module call
        tags = {
        Name = "Pavan-vpc1"
        }
}

resource "aws_internet_gateway" "gateway"{
        vpc_id = aws_vpc.vpc.id
}

resource "aws_route" "route"{
        route_table_id = aws_vpc.vpc.main_route_table_id
        destination_cidr_block = "0.0.0.0/0"
        gateway_id = aws_internet_gateway.gateway.id
}

data "aws_availability_zones" "availableAZ"{}

#output "AZs" {
#       description = "lets find out no of  AZ in region"
#       value = data.aws_availability_zones.availableAZ.names
#}

resource "aws_subnet" "main" {
        count = length(data.aws_availability_zones.availableAZ.names)
        vpc_id = aws_vpc.vpc.id
        cidr_block = "172.0.${count.index}.0/24"
        map_public_ip_on_launch = true
        availability_zone = element(data.aws_availability_zones.availableAZ.names,count.index)
}

resource "aws_security_group" "default" {
        name = "http-https-ssh-allow"
        description = "Allow HTTP, HTTPS and SSH Connetions"
        vpc_id = aws_vpc.vpc.id
        ingress {
                from_port = 22
                to_port = 22
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 80
                to_port = 80
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 443
                to_port = 443
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }
}

-------------------------------------------------------------------------------------------

  661  vi variables.tf
variable "cidr_block"{
        }

### No need to assign value for variables … we can set values while calling module

-------------------------------------
  663  cd ..
### Come back on HighLevel directory to write module
 
 666  vi main.tf

provider "aws" {
region = "ap-south-1"
}

module "aws_site1" {
source = "./aws_Site1"
cidr_block = "173.0.0.0/16"                           ## variable your aws_Site1 is looking for
}


========================================================


  667  ls
  668  terraform init
  669  terraform plan
==================================================
#####   Terraform Instance Demo with extension with previous Demo


[rps@localhost highLevel]$ cat main.tf
provider "aws" {
region = "ap-south-1"
}

module "aws_site1" {
source = "./aws_Site1"
cidr_block = "173.0.0.0/16"
ami = "ami-068257025f72f470d"
instance_type = "t2.micro"
key = "myTerraKey"
}
----------------------------------------------------
[rps@localhost highLevel]$ cat aws_Site1/variables.tf
variable "cidr_block"{
        }

variable "ami" {
}

variable "instance_type" {
}

variable "key" {
}

------------------------------------------------------------------------------

### Replace code of previous main .tf of aws_Site1 directory

[rps@localhost highLevel]$ cat aws_Site1/main.tf
resource "aws_vpc" "vpc" {
        cidr_block = var.cidr_block
        tags = {
        Name = "Pavan-vpc1"
        }
}

resource "aws_internet_gateway" "gateway"{
        vpc_id = aws_vpc.vpc.id
}

resource "aws_route" "route"{
        route_table_id = aws_vpc.vpc.main_route_table_id
        destination_cidr_block = "0.0.0.0/0"
        gateway_id = aws_internet_gateway.gateway.id
}

#data "aws_availability_zones" "availableAZ"{}

#output "AZs" {
#       description = "lets find out no of  AZ in region"
#       value = data.aws_availability_zones.availableAZ.names
#}

resource "aws_subnet" "main" {
#       count = length(data.aws_availability_zones.availableAZ.names)
        vpc_id = aws_vpc.vpc.id
        cidr_block = "173.0.10.0/24"
#       cidr_block = "173.0.${count.index}.0/24"
        map_public_ip_on_launch = true
#       availability_zone = element(data.aws_availability_zones.availableAZ.names,count.index)
}

resource "aws_security_group" "default" {
        name = "http-https-ssh-allow"
        description = "Allow HTTP, HTTPS and SSH Connections"
        vpc_id = aws_vpc.vpc.id
        ingress {
                from_port = 22
                to_port = 22
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 80
                to_port = 80
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 443
                to_port = 443
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }
}

resource "aws_instance" "ec2-instance" {
        ami = var.ami
        instance_type = var.instance_type
        key_name = var.key
        security_groups = [aws_security_group.default.id]
        subnet_id = aws_subnet.main.id
}

===============================================================
 rps@localhost highLevel]$  terraform apply
 
=======================================================

##### CICD With Jenkins

Create repo on git 
Clone it to terraform Controller
Under that directory add following 
-------

$ cat credentials.tf
provider "aws" {
region = var.region
access_key = var.accesskey
secret_key = var.secretkey
}

-----------------------------------
]$ cat variables.tf
variable "region" {
default = "ap-south-1"
type = string
}

variable "accesskey"{
sensitive = true
description = "MEntion your access key of IAM user"

}

variable "secretkey"{
sensitive = true
description = "MEntion your secret key of IAM user"
}

variable "ami" {
default = "ami-068257025f72f470d"
type = string
}

variable "instance_type" {
default = "t2.micro"
type = string
}

variable "key" {
default = "myTerraKey"
type = string
}

variable "cidr_block" {
default = "173.0.0.0/16"
type = string
}

variable "cidr_subnet" {
default = "173.0.1.0/24"
type = string
}

--------------------------------------------------------------

]$ cat main.tf
resource "aws_vpc" "vpc" {
        cidr_block = var.cidr_block
        tags = {
        Name = "Pavan-vpc1"
        }
}

resource "aws_internet_gateway" "gateway"{
        vpc_id = aws_vpc.vpc.id
}

resource "aws_route" "route"{
        route_table_id = aws_vpc.vpc.main_route_table_id
        destination_cidr_block = "0.0.0.0/0"
        gateway_id = aws_internet_gateway.gateway.id
}

#data "aws_availability_zones" "availableAZ"{}

#output "AZs" {
#       description = "lets find out no of  AZ in region"
#       value = data.aws_availability_zones.availableAZ.names
#}


resource "aws_subnet" "main" {
#       count = length(data.aws_availability_zones.availableAZ.names)
        vpc_id = aws_vpc.vpc.id
        cidr_block = var.cidr_subnet
#       cidr_block = "173.0.${count.index}.0/24"
        map_public_ip_on_launch = true
#       availability_zone = element(data.aws_availability_zones.availableAZ.names,count.index)
}

resource "aws_security_group" "default" {
        name = "http-https-ssh-allow"
        description = "Allow HTTP, HTTPS and SSH Connections"
        vpc_id = aws_vpc.vpc.id
        ingress {
                from_port = 22
                to_port = 22
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 80
                to_port = 80
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }

        ingress {
                from_port = 443
                to_port = 443
                protocol = "tcp"
                cidr_blocks = ["0.0.0.0/0"]
        }
}

resource "aws_instance" "ec2-instance" {
        ami = var.ami
        instance_type = var.instance_type
        key_name = var.key
        security_groups = [aws_security_group.default.id]
        subnet_id = aws_subnet.main.id
}

-----------------------------------------------------------------------------

### jenkins Installation on centos 

Long Term Support release
A LTS (Long-Term Support) release is chosen every 12 weeks from the stream of regular releases as the stable release for that time period. It can be installed from the redhat-stable yum repository.
sudo wget -O /etc/yum.repos.d/jenkins.repo \
    https://pkg.jenkins.io/redhat-stable/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key
sudo yum upgrade
# Add required dependencies for the jenkins package
sudo yum install java-11-openjdk
sudo yum install jenkins
sudo systemctl daemon-reload
 
###  Post Installation
 
⇐ Kubernetes
⇑ Installing Jenkins
Index
macOS ⇒
Linux 
Table of Contents
Prerequisites
Debian/Ubuntu
Long Term Support release
Weekly release
Installation of Java
Fedora
Long Term Support release
Weekly release
Start Jenkins
Red Hat / CentOS
Long Term Support release
Weekly release
Start Jenkins
Post-installation setup wizard
Unlocking Jenkins
Customizing Jenkins with plugins
Creating the first administrator user
Jenkins installers are available for several Linux distributions.
Debian/Ubuntu
Fedora
Red Hat / CentOS
Prerequisites
Minimum hardware requirements:
256 MB of RAM
1 GB of drive space (although 10 GB is a recommended minimum if running Jenkins as a Docker container)
Recommended hardware configuration for a small team:
4 GB+ of RAM
50 GB+ of drive space
Comprehensive hardware recommendations:
Hardware: see the Hardware Recommendations page
Software requirements:
Java: see the Java Requirements page
Web browser: see the Web Browser Compatibility page
For Windows operating system: Windows Support Policy
For Linux operating system: Linux Support Policy
Debian/Ubuntu
On Debian and Debian-based distributions like Ubuntu you can install Jenkins through apt.
Long Term Support release
A LTS (Long-Term Support) release is chosen every 12 weeks from the stream of regular releases as the stable release for that time period. It can be installed from the debian-stable apt repository.
curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo tee \
  /usr/share/keyrings/jenkins-keyring.asc > /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \
  https://pkg.jenkins.io/debian-stable binary/ | sudo tee \
  /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update
sudo apt-get install jenkins
Weekly release
A new release is produced weekly to deliver bug fixes and features to users and plugin developers. It can be installed from the debian apt repository.
curl -fsSL https://pkg.jenkins.io/debian/jenkins.io.key | sudo tee \
  /usr/share/keyrings/jenkins-keyring.asc > /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \
  https://pkg.jenkins.io/debian binary/ | sudo tee \
  /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update
sudo apt-get install jenkins
Beginning with Jenkins 2.335 and Jenkins 2.332.1, the package is configured with systemd rather than the older System V init. See the DigitalOcean community systemd tutorial to better understand the benefits of systemd and the systemctl command.
The package installation will:
Setup Jenkins as a daemon launched on start. Run systemctl cat jenkins for more details.
Create a ‘jenkins’ user to run this service.
Direct console log output to systemd-journald. Run journalctl -u jenkins.service if you are troubleshooting Jenkins.
Populate /lib/systemd/system/jenkins.service with configuration parameters for the launch, e.g JENKINS_HOME
Set Jenkins to listen on port 8080. Access this port with your browser to start configuration.
 
If Jenkins fails to start because a port is in use, run systemctl edit jenkins and add the following:
[Service]
Environment="JENKINS_PORT=8081"
Here, "8081" was chosen but you can put another port available.

Installation of Java
Jenkins requires Java in order to run, yet certain distributions don’t include this by default and some Java versions are incompatible with Jenkins.
There are multiple Java implementations which you can use. OpenJDK is the most popular one at the moment, we will use it in this guide.
Update the Debian apt repositories, install OpenJDK 11, and check the installation with the commands:
$ sudo apt update
$ sudo apt install openjdk-11-jre
$ java -version
openjdk version "11.0.12" 2021-07-20
OpenJDK Runtime Environment (build 11.0.12+7-post-Debian-2)
OpenJDK 64-Bit Server VM (build 11.0.12+7-post-Debian-2, mixed mode, sharing)
 
Why use apt and not apt-get or another command? The apt command has been available since 2014. It has a command structure that is similar to apt-get but was created to be a more pleasant experience for typical users. Simple software management tasks like install, search and remove are easier with apt.

Fedora
You can install Jenkins through dnf. You need to add the Jenkins repository from the Jenkins website to the package manager first.
Long Term Support release
A LTS (Long-Term Support) release is chosen every 12 weeks from the stream of regular releases as the stable release for that time period. It can be installed from the redhat-stable yum repository.
sudo wget -O /etc/yum.repos.d/jenkins.repo \
    https://pkg.jenkins.io/redhat-stable/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key
sudo dnf upgrade
# Add required dependencies for the jenkins package
sudo dnf install java-11-openjdk
sudo dnf install jenkins
sudo systemctl daemon-reload
Weekly release
A new release is produced weekly to deliver bug fixes and features to users and plugin developers. It can be installed from the redhat yum repository.
sudo wget -O /etc/yum.repos.d/jenkins.repo \
    https://pkg.jenkins.io/redhat/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key
sudo dnf upgrade
# Add required dependencies for the jenkins package
sudo dnf install java-11-openjdk
sudo dnf install jenkins
Start Jenkins
You can enable the Jenkins service to start at boot with the command:
sudo systemctl enable jenkins
You can start the Jenkins service with the command:
sudo systemctl start jenkins
You can check the status of the Jenkins service using the command:
sudo systemctl status jenkins
If everything has been set up correctly, you should see an output like this:
Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)
Active: active (running) since Tue 2018-11-13 16:19:01 +03; 4min 57s ago
 
If you have a firewall installed, you must add Jenkins as an exception. You must change YOURPORT in the script below to the port you want to use. Port 8080 is the most common.
YOURPORT=8080
PERM="--permanent"
SERV="$PERM --service=jenkins"

firewall-cmd $PERM --new-service=jenkins
firewall-cmd $SERV --set-short="Jenkins ports"
firewall-cmd $SERV --set-description="Jenkins port exceptions"
firewall-cmd $SERV --add-port=$YOURPORT/tcp
firewall-cmd $PERM --add-service=jenkins
firewall-cmd --zone=public --add-service=http --permanent
firewall-cmd --reload

Red Hat / CentOS
You can install Jenkins through yum on Red Hat Enterprise Linux, CentOS, and other Red Hat based distributions.
How To Install Jenkins on CentOS 7
You need to choose either the Jenkins Long Term Support release or the Jenkins weekly release.
Long Term Support release
A LTS (Long-Term Support) release is chosen every 12 weeks from the stream of regular releases as the stable release for that time period. It can be installed from the redhat-stable yum repository.
sudo wget -O /etc/yum.repos.d/jenkins.repo \
    https://pkg.jenkins.io/redhat-stable/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key
sudo yum upgrade
# Add required dependencies for the jenkins package
sudo yum install java-11-openjdk
sudo yum install jenkins
sudo systemctl daemon-reload
Weekly release
A new release is produced weekly to deliver bug fixes and features to users and plugin developers. It can be installed from the redhat yum repository.
sudo wget -O /etc/yum.repos.d/jenkins.repo \
    https://pkg.jenkins.io/redhat/jenkins.repo
sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key
sudo yum upgrade
# Add required dependencies for the jenkins package
sudo yum install java-11-openjdk
sudo yum install jenkins
Start Jenkins
You can enable the Jenkins service to start at boot with the command:
sudo systemctl enable jenkins
You can start the Jenkins service with the command:
sudo systemctl start jenkins
You can check the status of the Jenkins service using the command:
sudo systemctl status jenkins
 
firewall-cmd $SERV --add-port=8080/tcp
firewall-cmd --reload
=========================================
Reference :   https://www.jenkins.io/doc/book/installing/linux/


With Ip address of centos or localhost open port no 8080 in browser, Login to jenkins and create a free style project
==========================

#### LAST DAY DEMO

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

### AWS Secrets to store sensitive data 
========================================

### We plan to create aws secrets to store username and password of Mysql RDS database 

### How to create AWS Secret? And steps to follow

https://docs.google.com/document/d/1AypKokusLJYSF82o-XSnTaLqTQWd19uhZsCg5G2qc04/edit?usp=sharing

================================================================================



